{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v1 - dev",
      "provenance": [],
      "collapsed_sections": [
        "UnPgLO-a2L5V",
        "ycS7yK0y2Izc"
      ],
      "authorship_tag": "ABX9TyNYOndDXdLIRc4xiS7fuOTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedefliguer/trading/blob/master/v1_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpyze2fnDD08"
      },
      "source": [
        "## Instalación librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlDuK1EHQx4j"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SWGVvJZCmYl"
      },
      "source": [
        "## Detalle de funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfpAx_G0TbjQ"
      },
      "source": [
        "import yfinance as yf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import xgboost as xgb\r\n",
        "from xgboost.sklearn import XGBClassifier\r\n",
        "pd.options.mode.chained_assignment = None\r\n",
        "from datetime import date\r\n",
        "from datetime import timedelta \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import scipy.stats as st\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.ensemble import RandomForestClassifier \r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.metrics import fbeta_score\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "pd.set_option('display.max_columns', 400)\r\n",
        "pd.set_option('display.max_rows', 5000)\r\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQYnsTOCTlZ3"
      },
      "source": [
        "def descarga(ticker, fc_empieza, fc_termina):\r\n",
        "  base = yf.download(ticker, start=fc_empieza, end=fc_termina)\r\n",
        "  base = base[['Close', 'Volume', 'High', 'Low']]\r\n",
        "  base.insert(loc=0, column='Ticker', value=ticker)\r\n",
        "  base.reset_index(level=0, inplace=True)\r\n",
        "  base.columns=['fc', 'ticker', 'y', 'vl', 'high', 'low']\r\n",
        "  return base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oClKKS0zWr9f"
      },
      "source": [
        "def calcula_pc_merval(dataset):\r\n",
        "  dataset = pd.merge(dataset,mvl,on='fc',how='left')\r\n",
        "  dataset['pc_merval'] = dataset.y/dataset.mvl\r\n",
        "  dataset = dataset.drop(['mvl'], axis=1)\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uulgHlR-Xe2o"
      },
      "source": [
        "def calcula_amplitud(dataset):\r\n",
        "  dataset['amplitud'] = (dataset.high - dataset.low)/dataset.y\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBXvhAzXXzsW"
      },
      "source": [
        "def estandariza_volumen(dataset):\r\n",
        "  mean_vl = dataset['vl'].mean()\r\n",
        "  std_vl = dataset['vl'].std()\r\n",
        "  dataset['vl'] = (dataset.vl - mean_vl)/std_vl\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DclkiKuTzvG5"
      },
      "source": [
        "def calcula_medias(dataset):\r\n",
        "  period = 12\r\n",
        "  sma = dataset['y'].rolling(period, min_periods=period).mean()\r\n",
        "  idx_start = sma.isna().sum() + 1 - period\r\n",
        "  idx_end = idx_start + period\r\n",
        "  sma = sma[idx_start: idx_end]\r\n",
        "  rest = dataset['y'][idx_end:]\r\n",
        "  ema = pd.concat([sma, rest]).ewm(span=period, adjust=False).mean()\r\n",
        "  dataset['exp1'] = ema\r\n",
        "  period = 26\r\n",
        "  sma = dataset['y'].rolling(period, min_periods=period).mean()\r\n",
        "  idx_start = sma.isna().sum() + 1 - period\r\n",
        "  idx_end = idx_start + period\r\n",
        "  sma = sma[idx_start: idx_end]\r\n",
        "  rest = dataset['y'][idx_end:]\r\n",
        "  ema = pd.concat([sma, rest]).ewm(span=period, adjust=False).mean()\r\n",
        "  dataset['exp2'] = ema\r\n",
        "  macd = dataset['exp1']-dataset['exp2']\r\n",
        "  dataset['macd'] = macd\r\n",
        "  dataset['exp3'] = macd.ewm(span=9, adjust=False).mean()\r\n",
        "  dataset['histog'] = dataset['macd'] - dataset['exp3'] \r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0RVcwNiYW-n"
      },
      "source": [
        "def calcula_historia(dataset, lags):\r\n",
        "  for (columnName, columnData) in dataset.iloc[:,6:].iteritems():\r\n",
        "    i = 1\r\n",
        "    while i < lags:\r\n",
        "      colname = \"var_%s_%s\" % (columnName, i)\r\n",
        "      dataset[colname] = columnData/columnData.shift(i)-1\r\n",
        "      i = i + 1\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUhyPKRL3AKn"
      },
      "source": [
        "def calcula_canalidad_y(dataset):\r\n",
        "  i = 1\r\n",
        "  dataset['lag_y_1'] = dataset.y.shift(1)\r\n",
        "  dataset['nu_dias_y_entre_max_min_30'] = np.where((dataset['lag_y_1'] < dataset['high']) & (dataset['lag_y_1'] > dataset['low']), 1, 0)\r\n",
        "  dataset['nu_dias_y_entre_5pc_30'] = np.where((dataset['lag_y_1'] < (dataset.y * 1.05)) & (dataset['lag_y_1'] > (dataset.y * 0.95)), 1, 0)\r\n",
        "\r\n",
        "  dataset['nu_dias_y_entre_max_min_90'] = np.where((dataset['lag_y_1'] < dataset['high']) & (dataset['lag_y_1'] > dataset['low']), 1, 0)\r\n",
        "  dataset['nu_dias_y_entre_5pc_90'] = np.where((dataset['lag_y_1'] < (dataset.y * 1.05)) & (dataset['lag_y_1'] > (dataset.y * 0.95)), 1, 0)\r\n",
        "\r\n",
        "  dataset['nu_dias_y_entre_max_min_180'] = np.where((dataset['lag_y_1'] < dataset['high']) & (dataset['lag_y_1'] > dataset['low']), 1, 0)\r\n",
        "  dataset['nu_dias_y_entre_5pc_180'] = np.where((dataset['lag_y_1'] < (dataset.y * 1.05)) & (dataset['lag_y_1'] > (dataset.y * 0.95)), 1, 0)\r\n",
        "\r\n",
        "  dataset = dataset.drop(['lag_y_1'], axis=1)\r\n",
        "  i = 2\r\n",
        "  while i < 30:\r\n",
        "    colname = \"lag_y_%s\" % (i)\r\n",
        "    dataset[colname] = dataset.y.shift(i)\r\n",
        "    dataset['nu_dias_y_entre_max_min_30'] = dataset['nu_dias_y_entre_max_min_30'] + np.where((dataset[colname] < dataset['high']) & (dataset[colname] > dataset['low']), 1, 0)\r\n",
        "    dataset['nu_dias_y_entre_5pc_30'] = dataset['nu_dias_y_entre_5pc_30'] + np.where((dataset[colname] < (dataset.y * 1.05)) & (dataset[colname] > (dataset.y * 0.95)), 1, 0)\r\n",
        "    i = i + 1\r\n",
        "    dataset = dataset.drop([colname], axis=1)\r\n",
        "\r\n",
        "  i = 2\r\n",
        "  while i < 90:\r\n",
        "    colname = \"lag_y_%s\" % (i)\r\n",
        "    dataset[colname] = dataset.y.shift(i)\r\n",
        "    dataset['nu_dias_y_entre_max_min_90'] = dataset['nu_dias_y_entre_max_min_90'] + np.where((dataset[colname] < dataset['high']) & (dataset[colname] > dataset['low']), 1, 0)\r\n",
        "    dataset['nu_dias_y_entre_5pc_90'] = dataset['nu_dias_y_entre_5pc_90'] + np.where((dataset[colname] < (dataset.y * 1.05)) & (dataset[colname] > (dataset.y * 0.95)), 1, 0)\r\n",
        "    i = i + 1\r\n",
        "    dataset = dataset.drop([colname], axis=1)\r\n",
        "\r\n",
        "  i = 2\r\n",
        "  while i < 180:\r\n",
        "    colname = \"lag_y_%s\" % (i)\r\n",
        "    dataset[colname] = dataset.y.shift(i)\r\n",
        "    dataset['nu_dias_y_entre_max_min_180'] = dataset['nu_dias_y_entre_max_min_180'] + np.where((dataset[colname] < dataset['high']) & (dataset[colname] > dataset['low']), 1, 0)\r\n",
        "    dataset['nu_dias_y_entre_5pc_180'] = dataset['nu_dias_y_entre_5pc_180'] + np.where((dataset[colname] < (dataset.y * 1.05)) & (dataset[colname] > (dataset.y * 0.95)), 1, 0)\r\n",
        "    i = i + 1\r\n",
        "    dataset = dataset.drop([colname], axis=1)\r\n",
        "\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryqPlgcv5Vd1"
      },
      "source": [
        "def calcula_canalidad_histog_macd(dataset):\r\n",
        "  list = [5, 30, 90, 180]\r\n",
        "  for ventana in list:\r\n",
        "    i = 1\r\n",
        "    dataset['lag_histog_1'] = dataset.histog.shift(1)\r\n",
        "    colname_nu_1 = \"nu_dias_histog_entre_5pc_%s\" % (ventana)\r\n",
        "    dataset[colname_nu_1] = np.where((dataset['lag_histog_1'] < (dataset.histog * 1.05)) & (dataset['lag_histog_1'] > (dataset.histog * 0.95)), 1, 0)\r\n",
        "\r\n",
        "    colname_nu_2 = \"nu_dias_histog_positivo_%s\" % (ventana)\r\n",
        "    dataset[colname_nu_2] = np.where((dataset['lag_histog_1']>0), 1, 0)\r\n",
        "\r\n",
        "    colname_nu_3 = \"nu_dias_histog_negativo_%s\" % (ventana)\r\n",
        "    dataset[colname_nu_3] = np.where((dataset['lag_histog_1']<0), 1, 0)\r\n",
        "\r\n",
        "    colname_nu_4 = \"nu_dias_histog_mismo_signo_%s\" % (ventana)\r\n",
        "    dataset[colname_nu_4] = np.where(((dataset['lag_histog_1']>0) & (dataset['histog']>0))|((dataset['lag_histog_1']<0) & (dataset['histog']<0)), 1, 0)\r\n",
        "\r\n",
        "    dataset = dataset.drop(['lag_histog_1'], axis=1)\r\n",
        "    i = 2\r\n",
        "    while i < (ventana+1):\r\n",
        "      colname = \"lag_histog_%s\" % (i)\r\n",
        "      dataset[colname] = dataset.histog.shift(i)\r\n",
        "      dataset[colname_nu_1] = dataset[colname_nu_1] + np.where((dataset[colname] < (dataset.histog * 1.50)) & (dataset[colname] > (dataset.histog * 0.50)), 1, 0)\r\n",
        "      dataset[colname_nu_2] = dataset[colname_nu_2] + np.where((dataset[colname]>0), 1, 0)\r\n",
        "      dataset[colname_nu_3] = dataset[colname_nu_3] + np.where((dataset[colname]<0), 1, 0)\r\n",
        "      dataset[colname_nu_4] = dataset[colname_nu_4] + np.where(((dataset[colname]>0) & (dataset['histog']>0))|((dataset[colname]<0) & (dataset['histog']<0)), 1, 0)\r\n",
        "      i = i + 1\r\n",
        "      dataset = dataset.drop([colname], axis=1)\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fky3qlEu_KUU"
      },
      "source": [
        "def calcula_AT_tendencias(dataset, lags):\r\n",
        "  \r\n",
        "  # Construye las columnas para determinar si es un pico\r\n",
        "  i = 1\r\n",
        "  while i < (lags+1):\r\n",
        "      colname = 'p%sb' % (i)                                                  \r\n",
        "      dataset[colname] = round(dataset.y.shift(i),2)\r\n",
        "      j = i * -1\r\n",
        "      colname = 'p%sf' % (-j)                                                  \r\n",
        "      dataset[colname] = round(dataset.y.shift(j),2)\r\n",
        "      i = i + 1\r\n",
        "\r\n",
        "  # Determina si es un pico  \r\n",
        "  dataset['maxb'] = round(dataset.filter(regex=(\".*b\")).max(axis=1),2)\r\n",
        "  dataset['maxf']= round(dataset.filter(regex=(\".*f\")).max(axis=1),2)\r\n",
        "  dataset['minb'] = round(dataset.filter(regex=(\".*b\")).min(axis=1),2)\r\n",
        "  dataset['minf'] = round(dataset.filter(regex=(\".*f\")).min(axis=1),2)\r\n",
        "  dataset['T'] = np.where((dataset['y']>dataset['maxb']) & (dataset['y']>dataset['maxf']), 1, 0)\r\n",
        "  dataset['P'] = np.where((dataset['y']<dataset['minb']) & (dataset['y']<dataset['minf']), 1, 0)\r\n",
        "\r\n",
        "  techos = dataset[(dataset['T']==1)]\r\n",
        "  techos['m'] = (techos.y.shift(1) - techos.y)/(techos.fc.shift(1) - techos.fc).dt.days\r\n",
        "  techos.name = 'techos'\r\n",
        "  pisos = dataset[(dataset['P']==1)]\r\n",
        "  pisos['m'] = (pisos.y.shift(1) - pisos.y)/(pisos.fc.shift(1) - pisos.fc).dt.days\r\n",
        "  pisos.name = 'pisos'\r\n",
        "  dataset_list = [techos, pisos]\r\n",
        "\r\n",
        "  for dataset_picos in dataset_list:  # En cada dataset (techos y pisos)\r\n",
        "    name = dataset_picos.name\r\n",
        "    dias = len(dataset)\r\n",
        "    for index, row in dataset_picos.iloc[1:].iterrows(): # Para cada pico detectado (fila del dataset) a partir del segundo (porque el primero no tiene anterior, no tiene tendencia)\r\n",
        "      y_start = row['y']\r\n",
        "      pendiente = row['m']\r\n",
        "      if (dias < np.where(dataset.fc==row['fc'])[0] + lags):\r\n",
        "        continue    \r\n",
        "      serie = [] # Crea la serie que va a contener el precio proyectado\r\n",
        "      serie = np.append(serie, np.repeat(np.nan, (np.where(dataset.fc==row['fc'])[0] + lags))) # Appendea nulos hasta el día en el que confirmamos que nació una tendencia\r\n",
        "      i = np.where(dataset.fc==row['fc'])[0] + lags\r\n",
        "      while (i < dias):\r\n",
        "        dia = i - (np.where(dataset.fc==row['fc'])[0] + lags)\r\n",
        "        serie = np.append(serie, (y_start + pendiente*lags) + pendiente*dia)\r\n",
        "        i = i + 1 # Appendea el precio proyectado hasta el final\r\n",
        "\r\n",
        "      colname = '%s_%s_proy' % (name, index)  # Precio proyectado\r\n",
        "      dataset[colname] = serie # Construye la columna de toda la serie\r\n",
        "\r\n",
        "      # Construyo columna con veces en la que el pico fue superado\r\n",
        "      colname_pass = '%s_%s_pass' % (name, index) # Pico pasado\r\n",
        "      if name == 'techos':\r\n",
        "        dataset[colname_pass] = np.where(dataset['y']>(dataset[colname])*1.005, 1, 0)\r\n",
        "      elif name == 'pisos':\r\n",
        "        dataset[colname_pass] = np.where(dataset['y']<(dataset[colname])*0.995, 1, 0)\r\n",
        "      dataset[colname_pass] = dataset[colname_pass].cumsum()\r\n",
        "\r\n",
        "      # Construyo columna con veces en la que el pico fue probado\r\n",
        "      colname_prueba = '%s_%s_prueba' % (name, index)  \r\n",
        "      dataset[colname_prueba] = np.where((dataset['y']>dataset[colname]*0.995)&(dataset['y']<dataset[colname]*1.005), 1, 0)\r\n",
        "      dataset[colname_prueba] = dataset[colname_prueba].cumsum()\r\n",
        "\r\n",
        "      # Construyo columna con pendiente del pico\r\n",
        "      colname_pendiente = '%s_%s_pendiente' % (name, index)  \r\n",
        "      dataset[colname_pendiente] = row['m']\r\n",
        "\r\n",
        "      # Creo la combinacion y elimino cada uno\r\n",
        "      colname_comb = '%s_%s' % (name, index)\r\n",
        "      dataset[colname_comb] = dataset[[colname, colname_pass, colname_prueba, colname_pendiente]].values.tolist()\r\n",
        "      del dataset[colname]\r\n",
        "      del dataset[colname_pass]\r\n",
        "      del dataset[colname_prueba]\r\n",
        "      del dataset[colname_pendiente]\r\n",
        "\r\n",
        "  # Creo el objeto por cada techo o piso individual\r\n",
        "  names_techos = dataset.filter(regex=(\"(techos)(.*)\")).columns\r\n",
        "  names_pisos = dataset.filter(regex=(\"(pisos)(.*)\")).columns\r\n",
        "\r\n",
        "  for index, row in dataset.iterrows():  # Por cada fila del dataset original (por cada precio)\r\n",
        "\r\n",
        "    # Genero las rows vacías con las variables agregadas\r\n",
        "    nu_pruebas_techo_vivo_mas_probado = np.nan    \r\n",
        "    precio_proyectado_techo_vivo_mas_probado = np.nan\r\n",
        "    precio_proyectado_techo_vivo_mas_cercano = np.nan\r\n",
        "    precio_proyectado_techo_muerto_mas_cercano = np.nan\r\n",
        "    tendencia_techo_vivo_mas_probado = np.nan\r\n",
        "\r\n",
        "    nu_pruebas_piso_vivo_mas_probado = np.nan\r\n",
        "    precio_proyectado_piso_vivo_mas_probado = np.nan\r\n",
        "    precio_proyectado_piso_vivo_mas_cercano = np.nan\r\n",
        "    precio_proyectado_piso_muerto_mas_cercano = np.nan\r\n",
        "    tendencia_piso_vivo_mas_probado = np.nan\r\n",
        "\r\n",
        "    # Voy a recorrer cada tendencia proyectada para definir cuáles van, en caso de que corresponda lo asigno a estas variables agregadas\r\n",
        "\r\n",
        "    i = 0\r\n",
        "    while i < len(row.index): # Por cada uno de los picos de los que se puede armar tendencia\r\n",
        "      if (row.index[i] in names_techos):  # Si es un techo\r\n",
        "        if row[i][1]>5: # Si está muerto\r\n",
        "          if abs(row['y']-row[i][0]) < abs(row['y']-precio_proyectado_techo_muerto_mas_cercano) or np.isnan(precio_proyectado_techo_muerto_mas_cercano): # Si está muerto y proyecta precio más cercano que el actual\r\n",
        "            precio_proyectado_techo_muerto_mas_cercano = row[i][0]\r\n",
        "            \r\n",
        "        else: # Si está vivo\r\n",
        "          if row[i][2] > nu_pruebas_techo_vivo_mas_probado or (np.isnan(nu_pruebas_techo_vivo_mas_probado) and row[i][2]>0): # Si fue más probado que el actual\r\n",
        "            nu_pruebas_techo_vivo_mas_probado = row[i][2]\r\n",
        "            precio_proyectado_techo_vivo_mas_probado = row[i][0]\r\n",
        "            tendencia_techo_vivo_mas_probado = row[i][3]\r\n",
        "\r\n",
        "          if (np.isnan(precio_proyectado_techo_vivo_mas_cercano)) or (abs(row['y']-row[i][0]) < abs(row['y']-precio_proyectado_techo_vivo_mas_cercano)): # Si, sin haber muerto, proyecta un techo más alto que el actual\r\n",
        "            precio_proyectado_techo_vivo_mas_cercano = row[i][0]\r\n",
        "\r\n",
        "      elif (row.index[i] in names_pisos):\r\n",
        "        if row[i][1]>5: # Si está muerto\r\n",
        "          if abs(row['y']-row[i][0]) < abs(row['y']-precio_proyectado_piso_muerto_mas_cercano) or np.isnan(precio_proyectado_piso_muerto_mas_cercano): # Si proyecta precio más cercano que el actual\r\n",
        "            precio_proyectado_piso_muerto_mas_cercano = row[i][0]\r\n",
        "            \r\n",
        "        else: # Si está vivo\r\n",
        "          if row[i][2] > nu_pruebas_piso_vivo_mas_probado or (np.isnan(nu_pruebas_piso_vivo_mas_probado) and row[i][2]>0): # Si fue más probado que el actual\r\n",
        "            nu_pruebas_piso_vivo_mas_probado = row[i][2]\r\n",
        "            precio_proyectado_piso_vivo_mas_probado = row[i][0]\r\n",
        "            tendencia_piso_vivo_mas_probado = row[i][3]\r\n",
        "\r\n",
        "          if (np.isnan(precio_proyectado_piso_vivo_mas_cercano)) or (abs(row['y']-row[i][0]) < abs(row['y']-precio_proyectado_piso_vivo_mas_cercano)): # Si, sin haber muerto, proyecta un techo más alto que el actual\r\n",
        "            precio_proyectado_piso_vivo_mas_cercano = row[i][0]\r\n",
        "      i = i + 1\r\n",
        "        \r\n",
        "    dataset.loc[index,'nu_pruebas_techo_vivo_mas_probado_'f\"{lags}\"] = nu_pruebas_techo_vivo_mas_probado\r\n",
        "    dataset.loc[index,'precio_proyectado_techo_vivo_mas_probado_'f\"{lags}\"] = (precio_proyectado_techo_vivo_mas_probado - row['y'])/row['y']\r\n",
        "    dataset.loc[index,'precio_proyectado_techo_vivo_mas_cercano_'f\"{lags}\"] = (precio_proyectado_techo_vivo_mas_cercano - row['y'])/row['y']\r\n",
        "    dataset.loc[index,'precio_proyectado_techo_muerto_mas_cercano_'f\"{lags}\"] = (precio_proyectado_techo_muerto_mas_cercano - row['y'])/row['y']\r\n",
        "    dataset.loc[index,'tendencia_techo_vivo_mas_probado_'f\"{lags}\"] = tendencia_techo_vivo_mas_probado/row['y']\r\n",
        "\r\n",
        "    dataset.loc[index,'nu_pruebas_piso_vivo_mas_probado_'f\"{lags}\"] = nu_pruebas_piso_vivo_mas_probado\r\n",
        "    dataset.loc[index,'precio_proyectado_piso_vivo_mas_probado_'f\"{lags}\"] = (precio_proyectado_piso_vivo_mas_probado - row['y'])/row['y']\r\n",
        "    dataset.loc[index,'precio_proyectado_piso_vivo_mas_cercano_'f\"{lags}\"] = (precio_proyectado_piso_vivo_mas_cercano - row['y'])/row['y']\r\n",
        "    dataset.loc[index,'precio_proyectado_piso_muerto_mas_cercano_'f\"{lags}\"] = (precio_proyectado_piso_muerto_mas_cercano - row['y'])/row['y']\r\n",
        "    dataset.loc[index,'tendencia_piso_vivo_mas_probado_'f\"{lags}\"] = tendencia_piso_vivo_mas_probado/row['y']\r\n",
        "\r\n",
        "  # Elimino todas las que construí excepto estas\r\n",
        "  i = 1\r\n",
        "  while i < (lags+1):\r\n",
        "      colname = 'p%sb' % (i)                                                  \r\n",
        "      dataset = dataset.drop(colname, axis=1)\r\n",
        "      j = i * -1\r\n",
        "      colname = 'p%sf' % (-j)                                                  \r\n",
        "      dataset = dataset.drop(colname, axis=1)\r\n",
        "      i = i + 1\r\n",
        "\r\n",
        "  ultimas_drop = ['maxb', 'maxf', 'minb', 'minf', 'T', 'P']\r\n",
        "  dataset = dataset.drop(ultimas_drop, axis=1)\r\n",
        "  dataset = dataset.drop(names_techos, axis=1)\r\n",
        "  dataset = dataset.drop(names_pisos, axis=1)\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1p5ImqhvrrW"
      },
      "source": [
        "def calcula_target_class(dataset, SL, TG, dias_indeterminacion):\r\n",
        "  dataset['target'] = 99\r\n",
        "  i = 1\r\n",
        "  while i <= dias_indeterminacion:\r\n",
        "    var_y_low = dataset.low.shift(-i)/df.y-1 # Variación del mínimo de cada día contra el precio de compra\r\n",
        "    var_y_high = dataset.high.shift(-i)/df.y-1 # Variación del máximo de cada día contra el precio de compra\r\n",
        "    target = np.where(var_y_low < -SL, 0, 99)\r\n",
        "    target = np.where(var_y_high > TG, 1, target)\r\n",
        "    dataset['target'] = np.where(dataset['target'] == 99 , target , dataset['target'])\r\n",
        "    i = i + 1\r\n",
        "#  df = df.iloc[:-dias_indeterminacion]  # Elimino las últimas filas que no llegan a tener target\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU49lNHBZjif"
      },
      "source": [
        "def divide_dev_test(dataset, start_train, start_test, end_test):\r\n",
        "  global df, x_dev, y_dev, x_test, y_test, x_val, y_val, df_test, df_dev\r\n",
        "  month = dataset['fc'].dt.strftime('%Y%m')\r\n",
        "  month = pd.to_numeric(month)\r\n",
        "  if 'month' not in dataset:\r\n",
        "    dataset.insert (1, \"month\", month)\r\n",
        "  dataset = dataset[(dataset.target) < 90] # Elimina indeterminados\r\n",
        "\r\n",
        "  df_dev = dataset[(dataset.month >= start_train) & (dataset.month < start_test)]\r\n",
        "  df_test = dataset[(dataset.month >= start_test) & (dataset.month <= end_test)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdZ3VEj-Ch-M"
      },
      "source": [
        "## Consolidado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljjf2-cEUzC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8f129f-7d8e-474e-ea4f-30c4eb71df8d"
      },
      "source": [
        "dias_empieza = 5000\r\n",
        "dias_termina = 200\r\n",
        "today = date.today()\r\n",
        "fc_empieza = today + timedelta(days=(dias_empieza*-1))\r\n",
        "fc_termina = today + timedelta(days=(dias_termina*-1))\r\n",
        "\r\n",
        "mvl = yf.download('^MERV', start=fc_empieza, end=fc_termina)\r\n",
        "print(\"Descargado Merval\")\r\n",
        "mvl = mvl[['Close']]\r\n",
        "mvl.reset_index(level=0, inplace=True)\r\n",
        "mvl.columns=['fc','mvl']\r\n",
        "base = pd.DataFrame()\r\n",
        "\r\n",
        "for ticker in (\r\n",
        "    'GGAL.BA',\r\n",
        "    'BMA.BA',\r\n",
        "    'BYMA.BA',\r\n",
        "    'CEPU.BA',\r\n",
        "    'COME.BA',\r\n",
        "    'CRES.BA',\r\n",
        "    'CVH.BA',\r\n",
        "    'EDN.BA',\r\n",
        "    'MIRG.BA',\r\n",
        "    'PAMP.BA',\r\n",
        "    'SUPV.BA',\r\n",
        "    'TECO2.BA',\r\n",
        "    'TGNO4.BA',\r\n",
        "    'TGSU2.BA',\r\n",
        "    'TRAN.BA',\r\n",
        "    'VALO.BA',\r\n",
        "    'YPFD.BA'\r\n",
        "):\r\n",
        "  df = descarga(ticker, fc_empieza, fc_termina) # (Días empieza, días termina)\r\n",
        "  print(\"Descargado \", ticker)\r\n",
        "  df = calcula_pc_merval(df)\r\n",
        "  df = calcula_amplitud(df)\r\n",
        "  df = estandariza_volumen(df)\r\n",
        " \r\n",
        "  df = calcula_medias(df)\r\n",
        "  df = df.dropna()\r\n",
        "  df = calcula_historia(df, 5) # (Lags)\r\n",
        "  df = calcula_canalidad_y(df)\r\n",
        "  df = calcula_canalidad_histog_macd(df)\r\n",
        "\r\n",
        "  for per in (360, 120, 90, 60, 30, 15, 8, 4):\r\n",
        "    df = calcula_AT_tendencias(df,per)\r\n",
        "    print(\"Calculé AT para\", ticker, \"en lags de\", per)\r\n",
        "  \r\n",
        "  df = calcula_target_class(df, 0.06, 0.14, 90) # (Stop loss, Take gain, Días para indeterminación)\r\n",
        "  base = base.append(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado Merval\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  GGAL.BA\n",
            "Calculé AT para GGAL.BA en lags de 360\n",
            "Calculé AT para GGAL.BA en lags de 120\n",
            "Calculé AT para GGAL.BA en lags de 90\n",
            "Calculé AT para GGAL.BA en lags de 60\n",
            "Calculé AT para GGAL.BA en lags de 30\n",
            "Calculé AT para GGAL.BA en lags de 15\n",
            "Calculé AT para GGAL.BA en lags de 8\n",
            "Calculé AT para GGAL.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  BMA.BA\n",
            "Calculé AT para BMA.BA en lags de 360\n",
            "Calculé AT para BMA.BA en lags de 120\n",
            "Calculé AT para BMA.BA en lags de 90\n",
            "Calculé AT para BMA.BA en lags de 60\n",
            "Calculé AT para BMA.BA en lags de 30\n",
            "Calculé AT para BMA.BA en lags de 15\n",
            "Calculé AT para BMA.BA en lags de 8\n",
            "Calculé AT para BMA.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  BYMA.BA\n",
            "Calculé AT para BYMA.BA en lags de 360\n",
            "Calculé AT para BYMA.BA en lags de 120\n",
            "Calculé AT para BYMA.BA en lags de 90\n",
            "Calculé AT para BYMA.BA en lags de 60\n",
            "Calculé AT para BYMA.BA en lags de 30\n",
            "Calculé AT para BYMA.BA en lags de 15\n",
            "Calculé AT para BYMA.BA en lags de 8\n",
            "Calculé AT para BYMA.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  CEPU.BA\n",
            "Calculé AT para CEPU.BA en lags de 360\n",
            "Calculé AT para CEPU.BA en lags de 120\n",
            "Calculé AT para CEPU.BA en lags de 90\n",
            "Calculé AT para CEPU.BA en lags de 60\n",
            "Calculé AT para CEPU.BA en lags de 30\n",
            "Calculé AT para CEPU.BA en lags de 15\n",
            "Calculé AT para CEPU.BA en lags de 8\n",
            "Calculé AT para CEPU.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  COME.BA\n",
            "Calculé AT para COME.BA en lags de 360\n",
            "Calculé AT para COME.BA en lags de 120\n",
            "Calculé AT para COME.BA en lags de 90\n",
            "Calculé AT para COME.BA en lags de 60\n",
            "Calculé AT para COME.BA en lags de 30\n",
            "Calculé AT para COME.BA en lags de 15\n",
            "Calculé AT para COME.BA en lags de 8\n",
            "Calculé AT para COME.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  CRES.BA\n",
            "Calculé AT para CRES.BA en lags de 360\n",
            "Calculé AT para CRES.BA en lags de 120\n",
            "Calculé AT para CRES.BA en lags de 90\n",
            "Calculé AT para CRES.BA en lags de 60\n",
            "Calculé AT para CRES.BA en lags de 30\n",
            "Calculé AT para CRES.BA en lags de 15\n",
            "Calculé AT para CRES.BA en lags de 8\n",
            "Calculé AT para CRES.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  CVH.BA\n",
            "Calculé AT para CVH.BA en lags de 360\n",
            "Calculé AT para CVH.BA en lags de 120\n",
            "Calculé AT para CVH.BA en lags de 90\n",
            "Calculé AT para CVH.BA en lags de 60\n",
            "Calculé AT para CVH.BA en lags de 30\n",
            "Calculé AT para CVH.BA en lags de 15\n",
            "Calculé AT para CVH.BA en lags de 8\n",
            "Calculé AT para CVH.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  EDN.BA\n",
            "Calculé AT para EDN.BA en lags de 360\n",
            "Calculé AT para EDN.BA en lags de 120\n",
            "Calculé AT para EDN.BA en lags de 90\n",
            "Calculé AT para EDN.BA en lags de 60\n",
            "Calculé AT para EDN.BA en lags de 30\n",
            "Calculé AT para EDN.BA en lags de 15\n",
            "Calculé AT para EDN.BA en lags de 8\n",
            "Calculé AT para EDN.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  MIRG.BA\n",
            "Calculé AT para MIRG.BA en lags de 360\n",
            "Calculé AT para MIRG.BA en lags de 120\n",
            "Calculé AT para MIRG.BA en lags de 90\n",
            "Calculé AT para MIRG.BA en lags de 60\n",
            "Calculé AT para MIRG.BA en lags de 30\n",
            "Calculé AT para MIRG.BA en lags de 15\n",
            "Calculé AT para MIRG.BA en lags de 8\n",
            "Calculé AT para MIRG.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  PAMP.BA\n",
            "Calculé AT para PAMP.BA en lags de 360\n",
            "Calculé AT para PAMP.BA en lags de 120\n",
            "Calculé AT para PAMP.BA en lags de 90\n",
            "Calculé AT para PAMP.BA en lags de 60\n",
            "Calculé AT para PAMP.BA en lags de 30\n",
            "Calculé AT para PAMP.BA en lags de 15\n",
            "Calculé AT para PAMP.BA en lags de 8\n",
            "Calculé AT para PAMP.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  SUPV.BA\n",
            "Calculé AT para SUPV.BA en lags de 360\n",
            "Calculé AT para SUPV.BA en lags de 120\n",
            "Calculé AT para SUPV.BA en lags de 90\n",
            "Calculé AT para SUPV.BA en lags de 60\n",
            "Calculé AT para SUPV.BA en lags de 30\n",
            "Calculé AT para SUPV.BA en lags de 15\n",
            "Calculé AT para SUPV.BA en lags de 8\n",
            "Calculé AT para SUPV.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  TECO2.BA\n",
            "Calculé AT para TECO2.BA en lags de 360\n",
            "Calculé AT para TECO2.BA en lags de 120\n",
            "Calculé AT para TECO2.BA en lags de 90\n",
            "Calculé AT para TECO2.BA en lags de 60\n",
            "Calculé AT para TECO2.BA en lags de 30\n",
            "Calculé AT para TECO2.BA en lags de 15\n",
            "Calculé AT para TECO2.BA en lags de 8\n",
            "Calculé AT para TECO2.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  TGNO4.BA\n",
            "Calculé AT para TGNO4.BA en lags de 360\n",
            "Calculé AT para TGNO4.BA en lags de 120\n",
            "Calculé AT para TGNO4.BA en lags de 90\n",
            "Calculé AT para TGNO4.BA en lags de 60\n",
            "Calculé AT para TGNO4.BA en lags de 30\n",
            "Calculé AT para TGNO4.BA en lags de 15\n",
            "Calculé AT para TGNO4.BA en lags de 8\n",
            "Calculé AT para TGNO4.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  TGSU2.BA\n",
            "Calculé AT para TGSU2.BA en lags de 360\n",
            "Calculé AT para TGSU2.BA en lags de 120\n",
            "Calculé AT para TGSU2.BA en lags de 90\n",
            "Calculé AT para TGSU2.BA en lags de 60\n",
            "Calculé AT para TGSU2.BA en lags de 30\n",
            "Calculé AT para TGSU2.BA en lags de 15\n",
            "Calculé AT para TGSU2.BA en lags de 8\n",
            "Calculé AT para TGSU2.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  TRAN.BA\n",
            "Calculé AT para TRAN.BA en lags de 360\n",
            "Calculé AT para TRAN.BA en lags de 120\n",
            "Calculé AT para TRAN.BA en lags de 90\n",
            "Calculé AT para TRAN.BA en lags de 60\n",
            "Calculé AT para TRAN.BA en lags de 30\n",
            "Calculé AT para TRAN.BA en lags de 15\n",
            "Calculé AT para TRAN.BA en lags de 8\n",
            "Calculé AT para TRAN.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  VALO.BA\n",
            "Calculé AT para VALO.BA en lags de 360\n",
            "Calculé AT para VALO.BA en lags de 120\n",
            "Calculé AT para VALO.BA en lags de 90\n",
            "Calculé AT para VALO.BA en lags de 60\n",
            "Calculé AT para VALO.BA en lags de 30\n",
            "Calculé AT para VALO.BA en lags de 15\n",
            "Calculé AT para VALO.BA en lags de 8\n",
            "Calculé AT para VALO.BA en lags de 4\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Descargado  YPFD.BA\n",
            "Calculé AT para YPFD.BA en lags de 360\n",
            "Calculé AT para YPFD.BA en lags de 120\n",
            "Calculé AT para YPFD.BA en lags de 90\n",
            "Calculé AT para YPFD.BA en lags de 60\n",
            "Calculé AT para YPFD.BA en lags de 30\n",
            "Calculé AT para YPFD.BA en lags de 15\n",
            "Calculé AT para YPFD.BA en lags de 8\n",
            "Calculé AT para YPFD.BA en lags de 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAEl5i5BCqbL"
      },
      "source": [
        "## Working"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hSMIVe8qOIL"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnNxSV3Z1SzG"
      },
      "source": [
        "month = base['fc'].dt.strftime('%Y%m')\r\n",
        "month = pd.to_numeric(month)\r\n",
        "if 'month' not in base:\r\n",
        "  base.insert (1, \"month\", month)\r\n",
        "\r\n",
        "base = base[(base.target) < 90] # Elimina indeterminados\r\n",
        "base = base.sort_values(by=['fc'])\r\n",
        "un_quintos = int(len(base)/5)\r\n",
        "dos_quintos = int(len(base)/5)*2\r\n",
        "cuatro_quintos = int(len(base)/5)*4\r\n",
        "base_params = base.iloc[un_quintos:dos_quintos]\r\n",
        "base_train = base.iloc[dos_quintos:cuatro_quintos]\r\n",
        "base_test = base.iloc[cuatro_quintos:(len(base)-180)]\r\n",
        "\r\n",
        "# Parametrizo\r\n",
        "\r\n",
        "X=base_params.iloc[:, 7:].drop(\"target\", 1)\r\n",
        "targets=base_params.target\r\n",
        "\r\n",
        "pred_train, pred_test, tar_train, tar_test = train_test_split(X, targets, test_size=.4)\r\n",
        "eval_set = [(pred_train, tar_train),(pred_test, tar_test)]\r\n",
        "\r\n",
        "bst=XGBClassifier(objective= 'binary:logistic',seed=5)\r\n",
        "params = {  \r\n",
        "    \"n_estimators\": st.randint(15, 100),\r\n",
        "    \"max_depth\": st.randint(3, 4),\r\n",
        "    \"learning_rate\": st.uniform(0.05, 0.3),\r\n",
        "    \"colsample_bytree\": st.beta(10, 1) ,\r\n",
        "    \"subsample\": st.beta(10, 1)  ,\r\n",
        "    \"gamma\": st.uniform(0, 10),\r\n",
        "    'reg_alpha': st.expon(0, 50),\r\n",
        "    \"min_child_weight\": st.expon(0, 50)\r\n",
        "                         }\r\n",
        "gs = RandomizedSearchCV(bst, params,  n_iter=30, n_jobs=1,cv=4 )  \r\n",
        "bst=gs.fit(pred_train, tar_train,eval_set=eval_set, eval_metric=[\"auc\"],early_stopping_rounds=10) \r\n",
        "\r\n",
        "# Entreno\r\n",
        "\r\n",
        "X=base_train.iloc[:, 7:].drop(\"target\", 1)\r\n",
        "targets=base_train.target\r\n",
        "\r\n",
        "pred_train, pred_test, tar_train, tar_test = train_test_split(X, targets, test_size=.4)\r\n",
        "eval_set = [(pred_train, tar_train),(pred_test, tar_test)]\r\n",
        "\r\n",
        "classif = XGBClassifier(**bst.best_params_)\r\n",
        "model=classif.fit(pred_train,tar_train,eval_set=eval_set, eval_metric=[\"auc\"],early_stopping_rounds=10)\r\n",
        "results = model.evals_result()\r\n",
        "\r\n",
        "# Análisis\r\n",
        "\r\n",
        "epochs = len(results['validation_0']['auc'])\r\n",
        "x_axis = range(0, epochs)\r\n",
        "# plot log loss\r\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\r\n",
        "ax.plot(x_axis, results['validation_0']['auc'], label='Train')\r\n",
        "ax.plot(x_axis, results['validation_1']['auc'], label='Test')\r\n",
        "ax.legend()\r\n",
        "plt.ylabel('auc')\r\n",
        "plt.title('XGBoost auc')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "importancia=model.feature_importances_ \r\n",
        "importancia=pd.DataFrame(importancia)\r\n",
        "importancia=importancia.transpose()\r\n",
        "importancia.columns=X.columns\r\n",
        "b=importancia\r\n",
        "c=b.transpose()\r\n",
        "r=pd.DataFrame(c).loc[(c[0]>0),].sort_values([0],ascending=False)\r\n",
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "rZ6iA5O-Tmdt",
        "outputId": "a4e3eb09-c8e8-4bfd-deba-90b822d71f34"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a3ea5e73bef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pima.pickle.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIvk2VSORHwY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df2259e8-7d5c-4826-e7ca-1227df95082c"
      },
      "source": [
        "# Test\r\n",
        "\r\n",
        "X=base_test.iloc[:, 7:].drop(\"target\", 1)\r\n",
        "targets=base_test.target\r\n",
        "\r\n",
        "preds = model.predict_proba(X)\r\n",
        "A = preds[:,1]\r\n",
        "data_ks=pd.DataFrame(targets)\r\n",
        "data_ks['prob_suba'] = A\r\n",
        "data_ks['bucket'] = pd.qcut(data_ks.prob_suba, 50)\r\n",
        "data_ks['no_target'] = 1 - data_ks['target']\r\n",
        "grouped = data_ks.groupby('bucket', as_index = False)\r\n",
        "\r\n",
        "agg1 = grouped.min().prob_suba\r\n",
        "agg1 = pd.DataFrame({'min_prob_suba': grouped.min().prob_suba})\r\n",
        "agg1['max_prob_suba'] = grouped.max().prob_suba\r\n",
        "agg1['targets'] = grouped.sum().target\r\n",
        "agg1['no_targets'] = grouped.sum().no_target\r\n",
        "agg1['total'] = agg1.targets + agg1.no_targets\r\n",
        "agg1['ganancia_esperada'] = (agg1.targets/agg1.total)*(0.14-0.015) - (agg1.no_targets/agg1.total)*(0.06-0.015)\r\n",
        "\r\n",
        "agg1\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_prob_suba</th>\n",
              "      <th>max_prob_suba</th>\n",
              "      <th>targets</th>\n",
              "      <th>no_targets</th>\n",
              "      <th>total</th>\n",
              "      <th>ganancia_esperada</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.041509</td>\n",
              "      <td>0.156083</td>\n",
              "      <td>51</td>\n",
              "      <td>124</td>\n",
              "      <td>175</td>\n",
              "      <td>0.004543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.156198</td>\n",
              "      <td>0.182861</td>\n",
              "      <td>49</td>\n",
              "      <td>125</td>\n",
              "      <td>174</td>\n",
              "      <td>0.002874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.183014</td>\n",
              "      <td>0.202890</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>174</td>\n",
              "      <td>-0.005920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.202930</td>\n",
              "      <td>0.220885</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>174</td>\n",
              "      <td>-0.005920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.220893</td>\n",
              "      <td>0.234336</td>\n",
              "      <td>61</td>\n",
              "      <td>114</td>\n",
              "      <td>175</td>\n",
              "      <td>0.014257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.234430</td>\n",
              "      <td>0.249216</td>\n",
              "      <td>35</td>\n",
              "      <td>141</td>\n",
              "      <td>176</td>\n",
              "      <td>-0.011193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.249273</td>\n",
              "      <td>0.259604</td>\n",
              "      <td>38</td>\n",
              "      <td>134</td>\n",
              "      <td>172</td>\n",
              "      <td>-0.007442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.259620</td>\n",
              "      <td>0.273067</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>174</td>\n",
              "      <td>-0.005920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.273161</td>\n",
              "      <td>0.284112</td>\n",
              "      <td>59</td>\n",
              "      <td>115</td>\n",
              "      <td>174</td>\n",
              "      <td>0.012644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.284259</td>\n",
              "      <td>0.294934</td>\n",
              "      <td>52</td>\n",
              "      <td>123</td>\n",
              "      <td>175</td>\n",
              "      <td>0.005514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.294983</td>\n",
              "      <td>0.306769</td>\n",
              "      <td>52</td>\n",
              "      <td>122</td>\n",
              "      <td>174</td>\n",
              "      <td>0.005805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.306809</td>\n",
              "      <td>0.315773</td>\n",
              "      <td>55</td>\n",
              "      <td>119</td>\n",
              "      <td>174</td>\n",
              "      <td>0.008736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.315836</td>\n",
              "      <td>0.325264</td>\n",
              "      <td>53</td>\n",
              "      <td>121</td>\n",
              "      <td>174</td>\n",
              "      <td>0.006782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.325284</td>\n",
              "      <td>0.334272</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>175</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.334317</td>\n",
              "      <td>0.344210</td>\n",
              "      <td>41</td>\n",
              "      <td>133</td>\n",
              "      <td>174</td>\n",
              "      <td>-0.004943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.344215</td>\n",
              "      <td>0.354957</td>\n",
              "      <td>49</td>\n",
              "      <td>125</td>\n",
              "      <td>174</td>\n",
              "      <td>0.002874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.355051</td>\n",
              "      <td>0.365847</td>\n",
              "      <td>54</td>\n",
              "      <td>120</td>\n",
              "      <td>174</td>\n",
              "      <td>0.007759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.365850</td>\n",
              "      <td>0.374843</td>\n",
              "      <td>51</td>\n",
              "      <td>123</td>\n",
              "      <td>174</td>\n",
              "      <td>0.004828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.375057</td>\n",
              "      <td>0.384398</td>\n",
              "      <td>60</td>\n",
              "      <td>115</td>\n",
              "      <td>175</td>\n",
              "      <td>0.013286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.384450</td>\n",
              "      <td>0.393416</td>\n",
              "      <td>53</td>\n",
              "      <td>121</td>\n",
              "      <td>174</td>\n",
              "      <td>0.006782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.393453</td>\n",
              "      <td>0.402978</td>\n",
              "      <td>58</td>\n",
              "      <td>116</td>\n",
              "      <td>174</td>\n",
              "      <td>0.011667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.403050</td>\n",
              "      <td>0.412381</td>\n",
              "      <td>62</td>\n",
              "      <td>112</td>\n",
              "      <td>174</td>\n",
              "      <td>0.015575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.412409</td>\n",
              "      <td>0.420647</td>\n",
              "      <td>55</td>\n",
              "      <td>122</td>\n",
              "      <td>177</td>\n",
              "      <td>0.007825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.420832</td>\n",
              "      <td>0.429102</td>\n",
              "      <td>53</td>\n",
              "      <td>119</td>\n",
              "      <td>172</td>\n",
              "      <td>0.007384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.429169</td>\n",
              "      <td>0.438326</td>\n",
              "      <td>54</td>\n",
              "      <td>120</td>\n",
              "      <td>174</td>\n",
              "      <td>0.007759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.438379</td>\n",
              "      <td>0.447430</td>\n",
              "      <td>59</td>\n",
              "      <td>115</td>\n",
              "      <td>174</td>\n",
              "      <td>0.012644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.447454</td>\n",
              "      <td>0.455933</td>\n",
              "      <td>46</td>\n",
              "      <td>128</td>\n",
              "      <td>174</td>\n",
              "      <td>-0.000057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.456033</td>\n",
              "      <td>0.464546</td>\n",
              "      <td>49</td>\n",
              "      <td>126</td>\n",
              "      <td>175</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.464611</td>\n",
              "      <td>0.473667</td>\n",
              "      <td>50</td>\n",
              "      <td>124</td>\n",
              "      <td>174</td>\n",
              "      <td>0.003851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.473681</td>\n",
              "      <td>0.481739</td>\n",
              "      <td>55</td>\n",
              "      <td>119</td>\n",
              "      <td>174</td>\n",
              "      <td>0.008736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.481825</td>\n",
              "      <td>0.490992</td>\n",
              "      <td>58</td>\n",
              "      <td>116</td>\n",
              "      <td>174</td>\n",
              "      <td>0.011667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.491045</td>\n",
              "      <td>0.501732</td>\n",
              "      <td>50</td>\n",
              "      <td>125</td>\n",
              "      <td>175</td>\n",
              "      <td>0.003571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.501776</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>45</td>\n",
              "      <td>129</td>\n",
              "      <td>174</td>\n",
              "      <td>-0.001034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.512023</td>\n",
              "      <td>0.522510</td>\n",
              "      <td>52</td>\n",
              "      <td>122</td>\n",
              "      <td>174</td>\n",
              "      <td>0.005805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.522626</td>\n",
              "      <td>0.533417</td>\n",
              "      <td>54</td>\n",
              "      <td>120</td>\n",
              "      <td>174</td>\n",
              "      <td>0.007759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.533418</td>\n",
              "      <td>0.545709</td>\n",
              "      <td>78</td>\n",
              "      <td>96</td>\n",
              "      <td>174</td>\n",
              "      <td>0.031207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.545734</td>\n",
              "      <td>0.558394</td>\n",
              "      <td>51</td>\n",
              "      <td>124</td>\n",
              "      <td>175</td>\n",
              "      <td>0.004543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.558478</td>\n",
              "      <td>0.570152</td>\n",
              "      <td>57</td>\n",
              "      <td>117</td>\n",
              "      <td>174</td>\n",
              "      <td>0.010690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.570215</td>\n",
              "      <td>0.584017</td>\n",
              "      <td>57</td>\n",
              "      <td>117</td>\n",
              "      <td>174</td>\n",
              "      <td>0.010690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.584106</td>\n",
              "      <td>0.599753</td>\n",
              "      <td>55</td>\n",
              "      <td>119</td>\n",
              "      <td>174</td>\n",
              "      <td>0.008736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.600072</td>\n",
              "      <td>0.615647</td>\n",
              "      <td>53</td>\n",
              "      <td>122</td>\n",
              "      <td>175</td>\n",
              "      <td>0.006486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.615708</td>\n",
              "      <td>0.631816</td>\n",
              "      <td>66</td>\n",
              "      <td>110</td>\n",
              "      <td>176</td>\n",
              "      <td>0.018750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.631985</td>\n",
              "      <td>0.649055</td>\n",
              "      <td>57</td>\n",
              "      <td>115</td>\n",
              "      <td>172</td>\n",
              "      <td>0.011337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.649061</td>\n",
              "      <td>0.669233</td>\n",
              "      <td>65</td>\n",
              "      <td>109</td>\n",
              "      <td>174</td>\n",
              "      <td>0.018506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.669472</td>\n",
              "      <td>0.690382</td>\n",
              "      <td>67</td>\n",
              "      <td>107</td>\n",
              "      <td>174</td>\n",
              "      <td>0.020460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.690424</td>\n",
              "      <td>0.717721</td>\n",
              "      <td>68</td>\n",
              "      <td>107</td>\n",
              "      <td>175</td>\n",
              "      <td>0.021057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.717729</td>\n",
              "      <td>0.742355</td>\n",
              "      <td>61</td>\n",
              "      <td>113</td>\n",
              "      <td>174</td>\n",
              "      <td>0.014598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.742423</td>\n",
              "      <td>0.769720</td>\n",
              "      <td>64</td>\n",
              "      <td>110</td>\n",
              "      <td>174</td>\n",
              "      <td>0.017529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.770378</td>\n",
              "      <td>0.808562</td>\n",
              "      <td>64</td>\n",
              "      <td>110</td>\n",
              "      <td>174</td>\n",
              "      <td>0.017529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.808923</td>\n",
              "      <td>0.940466</td>\n",
              "      <td>101</td>\n",
              "      <td>74</td>\n",
              "      <td>175</td>\n",
              "      <td>0.053114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    min_prob_suba  max_prob_suba  targets  no_targets  total  ganancia_esperada\n",
              "0        0.041509       0.156083       51         124    175           0.004543\n",
              "1        0.156198       0.182861       49         125    174           0.002874\n",
              "2        0.183014       0.202890       40         134    174          -0.005920\n",
              "3        0.202930       0.220885       40         134    174          -0.005920\n",
              "4        0.220893       0.234336       61         114    175           0.014257\n",
              "5        0.234430       0.249216       35         141    176          -0.011193\n",
              "6        0.249273       0.259604       38         134    172          -0.007442\n",
              "7        0.259620       0.273067       40         134    174          -0.005920\n",
              "8        0.273161       0.284112       59         115    174           0.012644\n",
              "9        0.284259       0.294934       52         123    175           0.005514\n",
              "10       0.294983       0.306769       52         122    174           0.005805\n",
              "11       0.306809       0.315773       55         119    174           0.008736\n",
              "12       0.315836       0.325264       53         121    174           0.006782\n",
              "13       0.325284       0.334272       56         119    175           0.009400\n",
              "14       0.334317       0.344210       41         133    174          -0.004943\n",
              "15       0.344215       0.354957       49         125    174           0.002874\n",
              "16       0.355051       0.365847       54         120    174           0.007759\n",
              "17       0.365850       0.374843       51         123    174           0.004828\n",
              "18       0.375057       0.384398       60         115    175           0.013286\n",
              "19       0.384450       0.393416       53         121    174           0.006782\n",
              "20       0.393453       0.402978       58         116    174           0.011667\n",
              "21       0.403050       0.412381       62         112    174           0.015575\n",
              "22       0.412409       0.420647       55         122    177           0.007825\n",
              "23       0.420832       0.429102       53         119    172           0.007384\n",
              "24       0.429169       0.438326       54         120    174           0.007759\n",
              "25       0.438379       0.447430       59         115    174           0.012644\n",
              "26       0.447454       0.455933       46         128    174          -0.000057\n",
              "27       0.456033       0.464546       49         126    175           0.002600\n",
              "28       0.464611       0.473667       50         124    174           0.003851\n",
              "29       0.473681       0.481739       55         119    174           0.008736\n",
              "30       0.481825       0.490992       58         116    174           0.011667\n",
              "31       0.491045       0.501732       50         125    175           0.003571\n",
              "32       0.501776       0.511719       45         129    174          -0.001034\n",
              "33       0.512023       0.522510       52         122    174           0.005805\n",
              "34       0.522626       0.533417       54         120    174           0.007759\n",
              "35       0.533418       0.545709       78          96    174           0.031207\n",
              "36       0.545734       0.558394       51         124    175           0.004543\n",
              "37       0.558478       0.570152       57         117    174           0.010690\n",
              "38       0.570215       0.584017       57         117    174           0.010690\n",
              "39       0.584106       0.599753       55         119    174           0.008736\n",
              "40       0.600072       0.615647       53         122    175           0.006486\n",
              "41       0.615708       0.631816       66         110    176           0.018750\n",
              "42       0.631985       0.649055       57         115    172           0.011337\n",
              "43       0.649061       0.669233       65         109    174           0.018506\n",
              "44       0.669472       0.690382       67         107    174           0.020460\n",
              "45       0.690424       0.717721       68         107    175           0.021057\n",
              "46       0.717729       0.742355       61         113    174           0.014598\n",
              "47       0.742423       0.769720       64         110    174           0.017529\n",
              "48       0.770378       0.808562       64         110    174           0.017529\n",
              "49       0.808923       0.940466      101          74    175           0.053114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    }
  ]
}